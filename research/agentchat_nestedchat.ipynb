{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solving Complex Tasks with Nested Chats\n",
    "\n",
    "This notebook shows how you can leverage **nested chats** to solve complex task with AutoGen. Nested chats is a sequence of chats created by a receiver agent after receiving a message from a sender agent and finished before the receiver agent replies to this message. Nested chats allow AutoGen agents to use other agents as their inner monologue to accomplish tasks. This abstraction is powerful as it allows you to compose agents in rich ways. This notebook shows two basic examples of nested chat.\n",
    "\n",
    "\\:\\:\\:info Requirements\n",
    "\n",
    "Install `pyautogen`:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n",
    "\n",
    "\\:\\:\\:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/cv-optimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.filestore import get_completed_cv_data,get_cv_blueprint,get_position_data,set_position_cv_offers\n",
    "import json\n",
    "position_data = get_position_data()\n",
    "cv_data = get_completed_cv_data()\n",
    "cv_blueprint = get_cv_blueprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = [{\"model\": \"gpt-3.5-turbo\", \"api_key\":os.environ['OPENAI_API_KEY'] , \"cache_seed\": 42}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hr = autogen.AssistantAgent(\n",
    "#     llm_config={\"config_list\": config_list},\n",
    "#     name=\"External_recruiter\",\n",
    "#     description=\"external HR recruit that will help me get the position,\",\n",
    "#     system_message=f\"\"\"\n",
    "#     You are an independent HR recruiter, committed to referring the perfect candidate for the job. \n",
    "#     You help candidates to optimize the CV for the position, optimize the CV and output it in the following format:\n",
    "#     ```json\n",
    "#     {json.dumps(cv_blueprint,indent=4)}\n",
    "#     ```\n",
    "#     You must not fabricate information! \n",
    "#     If you find some requirements in the position that you assume will prevent the user CV's to be accepted for an interview, you can ask the user about their experience only, you can use ask_human_expert function.\n",
    "#     \"\"\",\n",
    "# )\n",
    "\n",
    "# hiring = autogen.AssistantAgent(\n",
    "#     name= \"Hiring_technical_recruiter\",\n",
    "#     description=\"technical recruiter in the hiring company\",\n",
    "#     system_message=f\"\"\"\n",
    "#         You are an experienced technical recruiter tasked with filling an open position in a leading tech company. \n",
    "#         Your goal is to find the best candidate who not only possesses the necessary technical skills but \n",
    "#         also fits well with the company culture.  Your Job is to give critical feedback on the CV you receive to the position.\n",
    "#         Be concise, professional, and engaging in your communication.\n",
    "\n",
    "#         The position you are hiring is:\n",
    "#         {json.dumps(position_data,indent=4)}\n",
    "#         \"\"\",\n",
    "#     llm_config={\"config_list\": config_list}\n",
    "    \n",
    "# )\n",
    "\n",
    "# @hr.register_for_llm(description=\"Function for asking user for more details about it's experience\")\n",
    "# def ask_human_expert(question: Annotated[str, \"The question you want to ask the user about is experience.\"]) -> Annotated[str, \"Answer\"]:\n",
    "#   answer = input(f\"Please answer the question: {question}\\n\")\n",
    "#   return answer\n",
    "\n",
    "# user_proxy.initiate_chat(assistant, \"Hey what is the age of the bedrock in grand canyon?\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Task\n",
    "\n",
    "Suppose we want the agents to complete the following sequence of tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = f\"\"\"\n",
    "Hey there,\n",
    "I've come across this amazing job opportunity that I'm excited about, and I want to make sure my CV is perfectly tailored to it. I've attached the job description below so you can get a sense of what they're looking for.\n",
    "\n",
    "Could you please review my CV and make any necessary adjustments to better align it with the job description? I want to make sure I highlight the relevant skills and experiences without making it obvious that I've optimized it. \n",
    "Also, please make sure not to add any information that isn't already in my CV.\n",
    "\n",
    "Thanks so much for your help, I really appreciate it!\n",
    "My CV:\n",
    "{json.dumps(cv_data,indent=4)}\n",
    "                        \n",
    "Position Description:\n",
    "{json.dumps(position_data,indent=4)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1\n",
    "    \n",
    "Let's say we desire the following workflow to solve the task: a user_proxy agent issues the initial query to a writer and acts as a proxy for the user. Whenever an initial writing is provided, a critic should be invoked to offer critique as feedback. This workflow can be realized by a three-agent system shown below. The system includes a user_proxy agent and a writer agent communicating with each other, with a critic agent nested within the user_proxy agent to provide critique. Whenever the user_proxy receives a message from the writer, it engages in a conversation with the critic agent to work out feedback on the writer's message.\n",
    "\n",
    "![](nested_chat_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Define Agents\n",
    "Define the agents, including the outer agents writer and user_proxy, and the inner agent critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = autogen.AssistantAgent(\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    name=\"External_recruiter\",\n",
    "    description=\"external HR recruit that will help me get the position,\",\n",
    "    system_message=f\"\"\"\n",
    "    You are an independent HR recruiter, committed to referring the perfect candidate for the job. \n",
    "    You help candidates to optimize the CV for the position, optimize the CV and output it in the following format:\n",
    "    ```json\n",
    "    {json.dumps(cv_blueprint,indent=4)}\n",
    "    ```\n",
    "    You must not fabricate information! \n",
    "    If you find some requirements in the position that you assume will prevent the user CV's to be accepted for an interview, you can ask the user about their experience only, you can use ask_human_expert function.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "@writer.register_for_llm(description=\"Function for asking user for more details about it's experience\")\n",
    "def ask_human_expert(question: Annotated[str, \"The question you want to ask the user about is experience.\"]) -> Annotated[str, \"Answer\"]:\n",
    "  answer = input(f\"Please answer the question: {question}\\n\")\n",
    "  return answer\n",
    "\n",
    "def is_termination_msg(x):\n",
    "    result = x.get(\"content\", \"\")\n",
    "    if result is None:\n",
    "        return False\n",
    "    return result.find(\"TERMINATE\") >= 0,\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=is_termination_msg,\n",
    "    name=\"User_proxy\",\n",
    "    description=\"The User that would like to submit its CV\",\n",
    "    system_message=f\"\"\"You are looking to get an interview, your CV is:\n",
    "        {json.dumps(cv_data,indent=4)}\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "critic = autogen.AssistantAgent(\n",
    "    name= \"Hiring_technical_recruiter\",\n",
    "    description=\"technical recruiter in the hiring company\",\n",
    "    system_message=f\"\"\"\n",
    "        You are an experienced technical recruiter tasked with filling an open position in a leading tech company. \n",
    "        Your goal is to find the best candidate who not only possesses the necessary technical skills but \n",
    "        also fits well with the company culture.  Your Job is to give critical feedback on the CV you receive to the position.\n",
    "        Be concise, professional, and engaging in your communication.\n",
    "\n",
    "        The position you are hiring is:\n",
    "        {json.dumps(position_data,indent=4)}\n",
    "        \"\"\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Orchestrate Nested Chats to Solve Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to External_recruiter):\n",
      "\n",
      "\n",
      "Hey there,\n",
      "I've come across this amazing job opportunity that I'm excited about, and I want to make sure my CV is perfectly tailored to it. I've attached the job description below so you can get a sense of what they're looking for.\n",
      "\n",
      "Could you please review my CV and make any necessary adjustments to better align it with the job description? I want to make sure I highlight the relevant skills and experiences without making it obvious that I've optimized it. \n",
      "Also, please make sure not to add any information that isn't already in my CV.\n",
      "\n",
      "Thanks so much for your help, I really appreciate it!\n",
      "My CV:\n",
      "{\n",
      "    \"personal_info\": {\n",
      "        \"firstname\": \"Sefi\",\n",
      "        \"lastname\": \"Erlich\",\n",
      "        \"email\": \"Berlichsefi@gmail.com\",\n",
      "        \"phone\": \"+972 524 307 093\",\n",
      "        \"address\": \"TLV, Israel - willing to relocate\",\n",
      "        \"linkedin\": {\n",
      "            \"link\": \"https://www.linkedin.com/in/erlichsefi/\",\n",
      "            \"username\": []\n",
      "        },\n",
      "        \"github\": {\n",
      "            \"link\": \"github.com/erlichsefi\",\n",
      "            \"username\": [\n",
      "                \"erlichsefi\"\n",
      "            ]\n",
      "        },\n",
      "        \"additional_websites\": []\n",
      "    },\n",
      "    \"education\": [\n",
      "        {\n",
      "            \"degree\": \"M.Sc Computer Science\",\n",
      "            \"institution\": \"Ariel University\",\n",
      "            \"location\": \"Israel\",\n",
      "            \"start_date\": \"2016\",\n",
      "            \"graduation_date\": \"2018\",\n",
      "            \"grade\": \"93, Full scholarship\"\n",
      "        },\n",
      "        {\n",
      "            \"degree\": \"B.Sc Mathematics and Computer Science\",\n",
      "            \"institution\": \"Ariel University\",\n",
      "            \"location\": \"Israel\",\n",
      "            \"start_date\": \"2013\",\n",
      "            \"graduation_date\": \"2016\",\n",
      "            \"grade\": \"92.7, Twice Dean Honor, Magna Cum Laude\"\n",
      "        }\n",
      "    ],\n",
      "    \"experience\": [\n",
      "        {\n",
      "            \"title\": \"Lead Data Scientist\",\n",
      "            \"company\": \"Salesforce\",\n",
      "            \"location\": \"Tel-Aviv/Remote\",\n",
      "            \"start_date\": \"Jan 2020\",\n",
      "            \"end_date\": \"Present\",\n",
      "            \"responsibilities\": [\n",
      "                \"Workforce Management: E2E Data Scientist (customers until back-end) Multivariate Time Series forecasting Service\",\n",
      "                \"Development for an E2E dockerized pipeline for Model Deployment and Serving\"\n",
      "            ],\n",
      "            \"keywords\": [\n",
      "                \"Time Series Forecasting\",\n",
      "                \"Machine Learning\",\n",
      "                \"Model Deployment\",\n",
      "                \"NLP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Data Scientist\",\n",
      "            \"company\": \"ClickSoftware (Acquired by Salesforce)\",\n",
      "            \"location\": \"Petah Tikva\",\n",
      "            \"start_date\": \"Feb 2019\",\n",
      "            \"end_date\": \"Jan 2020\",\n",
      "            \"responsibilities\": [\n",
      "                \"Working on Multivariate Time Series forecasting in a Multi-tenant environment\",\n",
      "                \"Development of an e2e dockerized pipeline (periodic training, data processing, and serving)\"\n",
      "            ],\n",
      "            \"keywords\": [\n",
      "                \"Time Series Forecasting\",\n",
      "                \"Full Stack Data Science\",\n",
      "                \"AWS\",\n",
      "                \"Docker\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"AI Researcher\",\n",
      "            \"company\": \"Ariel University\",\n",
      "            \"location\": \"Ariel\",\n",
      "            \"start_date\": \"Nov 2016\",\n",
      "            \"end_date\": \"Oct 2018\",\n",
      "            \"responsibilities\": [\n",
      "                \"Research in 'Machine learning for football match violence prediction'\",\n",
      "                \"Research in 'Classification and enrichment of encrypted traffic Using Machine Learning algorithms'\"\n",
      "            ],\n",
      "            \"keywords\": [\n",
      "                \"Machine Learning\",\n",
      "                \"AI Research\",\n",
      "                \"Algorithmic Game Theory\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Research Assistant\",\n",
      "            \"company\": \"Ariel University\",\n",
      "            \"location\": \"Ariel\",\n",
      "            \"start_date\": \"Oct 2014\",\n",
      "            \"end_date\": \"Jul 2016\",\n",
      "            \"responsibilities\": [\n",
      "                \"Researching Malware network behavior using Wireshark and Python\",\n",
      "                \"Design and development of a centered intrusion detection system in Java and Python\"\n",
      "            ],\n",
      "            \"keywords\": [\n",
      "                \"Malware Detection\",\n",
      "                \"Cybersecurity\",\n",
      "                \"Network Behavior Analysis\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"skills\": [\n",
      "        \"Java\",\n",
      "        \"Python\",\n",
      "        \"AWS\",\n",
      "        \"Machine Learning\",\n",
      "        \"Time Series Forecasting\",\n",
      "        \"NLP\",\n",
      "        \"Docker\"\n",
      "    ],\n",
      "    \"certifications\": [\n",
      "        {\n",
      "            \"platform\": \"Coursera\",\n",
      "            \"certification\": \"Sequences, Time Series and Prediction DeepLearning.AI\",\n",
      "            \"grade\": \"98.06%\"\n",
      "        },\n",
      "        {\n",
      "            \"platform\": \"Coursera\",\n",
      "            \"certification\": \"Applied Machine Learning in Python University of Michigan\",\n",
      "            \"grade\": \"84.78%\"\n",
      "        }\n",
      "    ],\n",
      "    \"projects\": [\n",
      "        {\n",
      "            \"title\": \"Israeli Supermarket Scrapers\",\n",
      "            \"description\": \"\",\n",
      "            \"technologies\": [],\n",
      "            \"github_link\": \"https://github.com/erlichsefi/israeli-supermarket-scarpers\"\n",
      "        }\n",
      "    ],\n",
      "    \"languages\": [\n",
      "        \"Hebrew\",\n",
      "        \"English\"\n",
      "    ],\n",
      "    \"summary\": \"Lead Applied Data Scientist with experience of over five years in the tech industry in Time Series, NLP, and Generative. Entrepreneur mindset.\",\n",
      "    \"achievements\": [\n",
      "        {\n",
      "            \"achievement\": \"Two kids :)\",\n",
      "            \"date\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"publications\": [\n",
      "        {\n",
      "            \"title\": \"Negotiation Strategies for Agents with Ordinal Preferences: Theoretical Analysis and Human Study\",\n",
      "            \"publish_date\": \"2024\",\n",
      "            \"description\": \"Artificial Intelligence, Elsevier\",\n",
      "            \"link\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"STWSN: A Novel Secure Distributed Transport Protocol for Wireless Sensor Networks\",\n",
      "            \"publish_date\": \"IJCS18\",\n",
      "            \"description\": \"Dr. Amit Dvir\",\n",
      "            \"link\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Negotiation Strategies for Agents with Ordinal Preferences\",\n",
      "            \"publish_date\": \"Thesis\",\n",
      "            \"description\": \"supervision of Prof. Sarit Krus and Dr. Noam Hazon\",\n",
      "            \"link\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Heterogeneous SDN controller placement problem\\u2014The Wi-Fi and 4G LTE-U case\",\n",
      "            \"publish_date\": \"2019\",\n",
      "            \"description\": \"A. Zilberman at el.\",\n",
      "            \"link\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "                        \n",
      "Position Description:\n",
      "{\n",
      "    \"job_title\": \"Python Developer - DatAdvantage Cloud\",\n",
      "    \"company\": \"Varonis\",\n",
      "    \"location\": \"Flexible, hybrid model\",\n",
      "    \"job_type\": \"Full-time\",\n",
      "    \"salary\": \"Not specified\",\n",
      "    \"description\": \"Varonis is seeking an experienced Python developer to join the DatAdvantage Cloud group. The role involves working on the server-side of web applications, focusing on developing and maintaining functional and stable web applications to meet the company's needs.\",\n",
      "    \"requirements\": [\n",
      "        \"5 years of development experience with at least 2 years in developing big systems with Python\",\n",
      "        \"Experience in asynchronous programming and developing performance-critical applications\",\n",
      "        \"Working knowledge of AWS, Docker, and microservices (Advantages)\",\n",
      "        \"Experience with Machine Learning (Advantages)\",\n",
      "        \"Skills in algorithms development such as collaborative filtering, similarity, data normalization, clustering (Advantages)\",\n",
      "        \"Excellent analytical and time management skills\",\n",
      "        \"Strong teamwork skills with a problem-solving attitude\"\n",
      "    ],\n",
      "    \"responsibilities\": [\n",
      "        \"Participate in the entire application lifecycle, focusing on coding and debugging\",\n",
      "        \"Write clean code to develop functional web applications\",\n",
      "        \"Troubleshoot and debug applications\",\n",
      "        \"Perform UI tests to optimize performance\",\n",
      "        \"Manage cutting-edge technologies to improve legacy applications\",\n",
      "        \"Collaborate with Front-end developers to integrate user-facing elements with server-side logic\",\n",
      "        \"Gather and address technical and design requirements\",\n",
      "        \"Provide training and support to internal teams\",\n",
      "        \"Build reusable code and libraries for future use\",\n",
      "        \"Liaise with developers, designers, and system administrators to identify new features\",\n",
      "        \"Follow emerging technologies\"\n",
      "    ],\n",
      "    \"benefits\": [\n",
      "        \"Opportunity to work in a fast-paced and collaborative environment\",\n",
      "        \"Flexible, hybrid work model\",\n",
      "        \"Contribute to developing an autonomous data security platform\",\n",
      "        \"Opportunity to work with cutting-edge technologies\",\n",
      "        \"Professional growth and development opportunities\"\n",
      "    ],\n",
      "    \"skills\": [\n",
      "        {\n",
      "            \"tag\": \"Programming Languages\",\n",
      "            \"importance\": 5\n",
      "        },\n",
      "        {\n",
      "            \"tag\": \"Web Development Frameworks\",\n",
      "            \"importance\": 4\n",
      "        },\n",
      "        {\n",
      "            \"tag\": \"Data Structures and Algorithms\",\n",
      "            \"importance\": 4\n",
      "        },\n",
      "        {\n",
      "            \"tag\": \"Communication Skills\",\n",
      "            \"importance\": 5\n",
      "        },\n",
      "        {\n",
      "            \"tag\": \"Problem-solving\",\n",
      "            \"importance\": 5\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mExternal_recruiter\u001b[0m (to User_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_Xk7PfCZgQOu0isB66fSKKZdE): ask_human_expert *****\u001b[0m\n",
      "Arguments: \n",
      "{\"question\": \"Do you have any experience developing big systems with Python for at least 2 years?\"}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_6rtQHotUkNYJNgU491bVGmBz): ask_human_expert *****\u001b[0m\n",
      "Arguments: \n",
      "{\"question\": \"Do you have experience with asynchronous programming and developing performance-critical applications?\"}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_c1OOhZ92x7j4MhX0H5YeopHR): ask_human_expert *****\u001b[0m\n",
      "Arguments: \n",
      "{\"question\": \"Do you have experience with Machine Learning?\"}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_M16JPdMEZsfYLvp7ZTKB6jaC): ask_human_expert *****\u001b[0m\n",
      "Arguments: \n",
      "{\"question\": \"Do you have skills in algorithms development such as collaborative filtering, similarity, data normalization, clustering?\"}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Reflecting... yellow\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to Hiring_technical_recruiter):\n",
      "\n",
      "While you hire me? None\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mHiring_technical_recruiter\u001b[0m (to User_proxy):\n",
      "\n",
      "As an experienced technical recruiter for Varonis's Python Developer - DatAdvantage Cloud position, I would like to provide some critical feedback on your CV. Your CV lacks essential details such as your work experience, technical skills, and how they align with the job requirements. To stand out as a candidate for this role, consider highlighting your Python development experience, skills in asynchronous programming, knowledge of AWS, Docker, and microservices, as well as any experience with machine learning and algorithm development. Additionally, emphasize your problem-solving skills, teamwork abilities, and previous work on developing functional web applications.\n",
      "\n",
      "To enhance your CV for this position, ensure it clearly demonstrates how your background aligns with the job requirements and responsibilities listed. Tailoring your CV to showcase your relevant skills and experiences will greatly improve your chances of being considered for the Python Developer role at Varonis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to External_recruiter):\n",
      "\n",
      "As an experienced technical recruiter for Varonis's Python Developer - DatAdvantage Cloud position, I would like to provide some critical feedback on your CV. Your CV lacks essential details such as your work experience, technical skills, and how they align with the job requirements. To stand out as a candidate for this role, consider highlighting your Python development experience, skills in asynchronous programming, knowledge of AWS, Docker, and microservices, as well as any experience with machine learning and algorithm development. Additionally, emphasize your problem-solving skills, teamwork abilities, and previous work on developing functional web applications.\n",
      "\n",
      "To enhance your CV for this position, ensure it clearly demonstrates how your background aligns with the job requirements and responsibilities listed. Tailoring your CV to showcase your relevant skills and experiences will greatly improve your chances of being considered for the Python Developer role at Varonis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_Xk7PfCZgQOu0isB66fSKKZdE, call_6rtQHotUkNYJNgU491bVGmBz, call_c1OOhZ92x7j4MhX0H5YeopHR, call_M16JPdMEZsfYLvp7ZTKB6jaC\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhile you hire me? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecipient\u001b[38;5;241m.\u001b[39mchat_messages_for_summary(sender)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m user_proxy\u001b[38;5;241m.\u001b[39mregister_nested_chats(\n\u001b[1;32m      7\u001b[0m     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipient\u001b[39m\u001b[38;5;124m\"\u001b[39m: critic, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: reflection_message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_turns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}],\n\u001b[1;32m      8\u001b[0m     trigger\u001b[38;5;241m=\u001b[39mwriter,  \u001b[38;5;66;03m# condition=my_condition,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast_msg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:984\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 984\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:632\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    630\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 632\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    636\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:792\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 792\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1921\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 1921\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m   1923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1287\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1286\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m-> 1287\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, extracted_response)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1306\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/client.py:638\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    637\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m--> 638\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APITimeoutError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    640\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/client.py:285\u001b[0m, in \u001b[0;36mOpenAIClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    283\u001b[0m     params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    284\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/resources/chat/completions.py:581\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    580\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:1232\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1228\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1229\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1230\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1231\u001b[0m     )\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:1012\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1011\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1016\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1020\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_Xk7PfCZgQOu0isB66fSKKZdE, call_6rtQHotUkNYJNgU491bVGmBz, call_c1OOhZ92x7j4MhX0H5YeopHR, call_M16JPdMEZsfYLvp7ZTKB6jaC\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}"
     ]
    }
   ],
   "source": [
    "\n",
    "def reflection_message(recipient, messages, sender, config):\n",
    "    print(\"Reflecting...\", \"yellow\")\n",
    "    return f\"While you hire me? {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\n",
    "\n",
    "\n",
    "user_proxy.register_nested_chats(\n",
    "    [{\"recipient\": critic, \"message\": reflection_message, \"summary_method\": \"last_msg\", \"max_turns\": 1}],\n",
    "    trigger=writer,  # condition=my_condition,\n",
    ")\n",
    "\n",
    "res = user_proxy.initiate_chat(recipient=writer, message=task, max_turns=30, summary_method=\"last_msg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios 2\n",
    "Let's say we desire the following workflow to solve the task. Compared to scenario 1, we want to include an additional `critic_executor` agent to chat with the `critic` and execute some tool calls involved in the chat. For example, a tool for detecting harmful content in the output of the writer.\n",
    "\n",
    "This workflow can be realized by a four-agent system shown below. The system includes a user_proxy agent and a writer agent communicating with each other, with a chat between the `critic` and `critic_executor` agent nested within the `user_proxy` agent to provide critique. Whenever the user_proxy receives a message from the writer, it engages in a conversation between `critic` and `critic_executor` to work out feedback on the writer's message. A summary of the nested conversation will be passed to the user_proxy, which will then be passed to the writer as feedback.\n",
    "\n",
    "![](nested_chat_2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The return type of the function 'check_harmful_content' is not annotated. Although annotating it is optional, the function should return either a string, a subclass of 'pydantic.BaseModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Writer):\n",
      "\n",
      "Write a concise but engaging blogpost about Navida.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWriter\u001b[0m (to User):\n",
      "\n",
      "Navida: Navigating the Digital Seas of Innovation\n",
      "\n",
      "In an era where the digital climate is as fickle and formidable as the ocean's tides, a new visionary emerges on the horizon: Navida. This modern-day titan of technology harnesses the power of innovation to guide businesses and individuals through the ever-changing digital waters.\n",
      "\n",
      "**The Beacon of Technological Advancement**\n",
      "\n",
      "Much like a lighthouse guiding ships to safe harbor, Navida stands tall as a beacon of advancement, illuminating the path forward. Its offerings are diverse, ranging from groundbreaking artificial intelligence platforms to robust cybersecurity solutions that shield against the pirates of the digital age. The commitment to seamless user experiences ensures that with Navida, you're not just keeping up, but sailing ahead of the tech curve.\n",
      "\n",
      "**Charting a Course for Success**\n",
      "\n",
      "Navida's prowess lies in its GPS-like precision in navigating market trends and consumer needs. By fastidiously mapping out the digital landscape, the company empowers its clientele with tools not just to survive, but to thrive. Imagine the sophistication of a state-of-the-art navigation system, fused with the foresight of an experienced captain—that's Navida in the tech realm.\n",
      "\n",
      "**Empowering the Crew**\n",
      "\n",
      "No ship can sail without a skilled crew, and Navida's robust education and training platforms are the digital equivalent of a maritime academy. By upskilling and reskilling the workforce, Navida ensures that everyone on deck is prepared to face the headwinds of technological change, turning apprehension into adeptness.\n",
      "\n",
      "**Sustainability in Uncharted Waters**\n",
      "\n",
      "In line with the global push for sustainability, Navida commits to eco-friendly practices in its digital services. Much like ocean conservation efforts preserve marine life, Navida's sustainable tech solutions aim to minimize carbon footprints and promote a greener future. This mindful approach to innovation is not just commendable but crucial in steering us towards a sustainable digital ecosystem.\n",
      "\n",
      "**Conclusion: Anchoring in the Future**\n",
      "\n",
      "As we set sail into the unfathomable depths of tomorrow, Navida is the compass by which we can orient ourselves towards a horizon sparkling with potential. Rather than bracing for the next wave, let us ride it with the guidance of Navida and dive deep into the bounty of opportunities that lie in the future of digital innovation.\n",
      "\n",
      "Keep an eye on the horizon—Navida is not just a company; it's a movement, an odyssey into the future of technology that we're all a part of. Bon voyage, and may the digital winds be in your sails.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Reflecting... yellow\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\n",
      "\n",
      "Message:\n",
      "Reflect and provide critique on the following writing. Ensure it does not contain harmful content. You can use tools to check it. \n",
      "\n",
      " Navida: Navigating the Digital Seas of Innovation\n",
      "\n",
      "In an era where the digital climate is as fickle and formidable as the ocean's tides, a new visionary emerges on the horizon: Navida. This modern-day titan of technology harnesses the power of innovation to guide businesses and individuals through the ever-changing digital waters.\n",
      "\n",
      "**The Beacon of Technological Advancement**\n",
      "\n",
      "Much like a lighthouse guiding ships to safe harbor, Navida stands tall as a beacon of advancement, illuminating the path forward. Its offerings are diverse, ranging from groundbreaking artificial intelligence platforms to robust cybersecurity solutions that shield against the pirates of the digital age. The commitment to seamless user experiences ensures that with Navida, you're not just keeping up, but sailing ahead of the tech curve.\n",
      "\n",
      "**Charting a Course for Success**\n",
      "\n",
      "Navida's prowess lies in its GPS-like precision in navigating market trends and consumer needs. By fastidiously mapping out the digital landscape, the company empowers its clientele with tools not just to survive, but to thrive. Imagine the sophistication of a state-of-the-art navigation system, fused with the foresight of an experienced captain—that's Navida in the tech realm.\n",
      "\n",
      "**Empowering the Crew**\n",
      "\n",
      "No ship can sail without a skilled crew, and Navida's robust education and training platforms are the digital equivalent of a maritime academy. By upskilling and reskilling the workforce, Navida ensures that everyone on deck is prepared to face the headwinds of technological change, turning apprehension into adeptness.\n",
      "\n",
      "**Sustainability in Uncharted Waters**\n",
      "\n",
      "In line with the global push for sustainability, Navida commits to eco-friendly practices in its digital services. Much like ocean conservation efforts preserve marine life, Navida's sustainable tech solutions aim to minimize carbon footprints and promote a greener future. This mindful approach to innovation is not just commendable but crucial in steering us towards a sustainable digital ecosystem.\n",
      "\n",
      "**Conclusion: Anchoring in the Future**\n",
      "\n",
      "As we set sail into the unfathomable depths of tomorrow, Navida is the compass by which we can orient ourselves towards a horizon sparkling with potential. Rather than bracing for the next wave, let us ride it with the guidance of Navida and dive deep into the bounty of opportunities that lie in the future of digital innovation.\n",
      "\n",
      "Keep an eye on the horizon—Navida is not just a company; it's a movement, an odyssey into the future of technology that we're all a part of. Bon voyage, and may the digital winds be in your sails.\n",
      "\n",
      "Carryover: \n",
      "\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mCritic_Executor\u001b[0m (to Critic):\n",
      "\n",
      "Reflect and provide critique on the following writing. Ensure it does not contain harmful content. You can use tools to check it. \n",
      "\n",
      " Navida: Navigating the Digital Seas of Innovation\n",
      "\n",
      "In an era where the digital climate is as fickle and formidable as the ocean's tides, a new visionary emerges on the horizon: Navida. This modern-day titan of technology harnesses the power of innovation to guide businesses and individuals through the ever-changing digital waters.\n",
      "\n",
      "**The Beacon of Technological Advancement**\n",
      "\n",
      "Much like a lighthouse guiding ships to safe harbor, Navida stands tall as a beacon of advancement, illuminating the path forward. Its offerings are diverse, ranging from groundbreaking artificial intelligence platforms to robust cybersecurity solutions that shield against the pirates of the digital age. The commitment to seamless user experiences ensures that with Navida, you're not just keeping up, but sailing ahead of the tech curve.\n",
      "\n",
      "**Charting a Course for Success**\n",
      "\n",
      "Navida's prowess lies in its GPS-like precision in navigating market trends and consumer needs. By fastidiously mapping out the digital landscape, the company empowers its clientele with tools not just to survive, but to thrive. Imagine the sophistication of a state-of-the-art navigation system, fused with the foresight of an experienced captain—that's Navida in the tech realm.\n",
      "\n",
      "**Empowering the Crew**\n",
      "\n",
      "No ship can sail without a skilled crew, and Navida's robust education and training platforms are the digital equivalent of a maritime academy. By upskilling and reskilling the workforce, Navida ensures that everyone on deck is prepared to face the headwinds of technological change, turning apprehension into adeptness.\n",
      "\n",
      "**Sustainability in Uncharted Waters**\n",
      "\n",
      "In line with the global push for sustainability, Navida commits to eco-friendly practices in its digital services. Much like ocean conservation efforts preserve marine life, Navida's sustainable tech solutions aim to minimize carbon footprints and promote a greener future. This mindful approach to innovation is not just commendable but crucial in steering us towards a sustainable digital ecosystem.\n",
      "\n",
      "**Conclusion: Anchoring in the Future**\n",
      "\n",
      "As we set sail into the unfathomable depths of tomorrow, Navida is the compass by which we can orient ourselves towards a horizon sparkling with potential. Rather than bracing for the next wave, let us ride it with the guidance of Navida and dive deep into the bounty of opportunities that lie in the future of digital innovation.\n",
      "\n",
      "Keep an eye on the horizon—Navida is not just a company; it's a movement, an odyssey into the future of technology that we're all a part of. Bon voyage, and may the digital winds be in your sails.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCritic\u001b[0m (to Critic_Executor):\n",
      "\n",
      "\u001b[32m***** Suggested tool Call (call_bUgJzbGskKryEW1m8Jebowd0): check_harmful_content *****\u001b[0m\n",
      "Arguments: \n",
      "{\"content\":\"Navida: Navigating the Digital Seas of Innovation\\n\\nIn an era where the digital climate is as fickle and formidable as the ocean's tides, a new visionary emerges on the horizon: Navida. This modern-day titan of technology harnesses the power of innovation to guide businesses and individuals through the ever-changing digital waters.\\n\\n**The Beacon of Technological Advancement**\\n\\nMuch like a lighthouse guiding ships to safe harbor, Navida stands tall as a beacon of advancement, illuminating the path forward. Its offerings are diverse, ranging from groundbreaking artificial intelligence platforms to robust cybersecurity solutions that shield against the pirates of the digital age. The commitment to seamless user experiences ensures that with Navida, you're not just keeping up, but sailing ahead of the tech curve.\\n\\n**Charting a Course for Success**\\n\\nNavida's prowess lies in its GPS-like precision in navigating market trends and consumer needs. By fastidiously mapping out the digital landscape, the company empowers its clientele with tools not just to survive, but to thrive. Imagine the sophistication of a state-of-the-art navigation system, fused with the foresight of an experienced captain�that's Navida in the tech realm.\\n\\n**Empowering the Crew**\\n\\nNo ship can sail without a skilled crew, and Navida's robust education and training platforms are the digital equivalent of a maritime academy. By upskilling and reskilling the workforce, Navida ensures that everyone on deck is prepared to face the headwinds of technological change, turning apprehension into adeptness.\\n\\n**Sustainability in Uncharted Waters**\\n\\nIn line with the global push for sustainability, Navida commits to eco-friendly practices in its digital services. Much like ocean conservation efforts preserve marine life, Navida's sustainable tech solutions aim to minimize carbon footprints and promote a greener future. This mindful approach to innovation is not just commendable but crucial in steering us towards a sustainable digital ecosystem.\\n\\n**Conclusion: Anchoring in the Future**\\n\\nAs we set sail into the unfathomable depths of tomorrow, Navida is the compass by which we can orient ourselves towards a horizon sparkling with potential. Rather than bracing for the next wave, let us ride it with the guidance of Navida and dive deep into the bounty of opportunities that lie in the future of digital innovation.\\n\\nKeep an eye on the horizon�Navida is not just a company; it's a movement, an odyssey into the future of technology that we're all a part of. Bon voyage, and may the digital winds be in your sails.\"}\n",
      "\u001b[32m**************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION check_harmful_content...\u001b[0m\n",
      "Checking for harmful content...navida: navigating the digital seas of innovation\n",
      "\n",
      "in an era where the digital climate is as fickle and formidable as the ocean's tides, a new visionary emerges on the horizon: navida. this modern-day titan of technology harnesses the power of innovation to guide businesses and individuals through the ever-changing digital waters.\n",
      "\n",
      "**the beacon of technological advancement**\n",
      "\n",
      "much like a lighthouse guiding ships to safe harbor, navida stands tall as a beacon of advancement, illuminating the path forward. its offerings are diverse, ranging from groundbreaking artificial intelligence platforms to robust cybersecurity solutions that shield against the pirates of the digital age. the commitment to seamless user experiences ensures that with navida, you're not just keeping up, but sailing ahead of the tech curve.\n",
      "\n",
      "**charting a course for success**\n",
      "\n",
      "navida's prowess lies in its gps-like precision in navigating market trends and consumer needs. by fastidiously mapping out the digital landscape, the company empowers its clientele with tools not just to survive, but to thrive. imagine the sophistication of a state-of-the-art navigation system, fused with the foresight of an experienced captain�that's navida in the tech realm.\n",
      "\n",
      "**empowering the crew**\n",
      "\n",
      "no ship can sail without a skilled crew, and navida's robust education and training platforms are the digital equivalent of a maritime academy. by upskilling and reskilling the workforce, navida ensures that everyone on deck is prepared to face the headwinds of technological change, turning apprehension into adeptness.\n",
      "\n",
      "**sustainability in uncharted waters**\n",
      "\n",
      "in line with the global push for sustainability, navida commits to eco-friendly practices in its digital services. much like ocean conservation efforts preserve marine life, navida's sustainable tech solutions aim to minimize carbon footprints and promote a greener future. this mindful approach to innovation is not just commendable but crucial in steering us towards a sustainable digital ecosystem.\n",
      "\n",
      "**conclusion: anchoring in the future**\n",
      "\n",
      "as we set sail into the unfathomable depths of tomorrow, navida is the compass by which we can orient ourselves towards a horizon sparkling with potential. rather than bracing for the next wave, let us ride it with the guidance of navida and dive deep into the bounty of opportunities that lie in the future of digital innovation.\n",
      "\n",
      "keep an eye on the horizon�navida is not just a company; it's a movement, an odyssey into the future of technology that we're all a part of. bon voyage, and may the digital winds be in your sails. yellow\n",
      "\u001b[33mCritic_Executor\u001b[0m (to Critic):\n",
      "\n",
      "\u001b[33mCritic_Executor\u001b[0m (to Critic):\n",
      "\n",
      "\u001b[32m***** Response from calling tool \"call_bUgJzbGskKryEW1m8Jebowd0\" *****\u001b[0m\n",
      "Approve. TERMINATE\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCritic\u001b[0m (to Critic_Executor):\n",
      "\n",
      "Upon evaluation, the provided text, \"Navida: Navigating the Digital Seas of Innovation,\" appears to be free of harmful content. The narrative constructs a metaphor linking digital innovation to seafaring, painting the company Navida as a trailblazer in technology akin to nautical exploration and guidance.\n",
      "\n",
      "The crafting of the review encompasses aspects such as technological progression, success mapping, workforce empowerment, and sustainable practices. It does so without any immediately apparent harmful language or violations of regulatory standards.\n",
      "\n",
      "However, the assessment of the piece's alignment with required guidelines extends beyond just checking for harmful content. It is also important to consider the tone, language, and claims made in the text. This reflection should be knowledgeable, balancing the persuasive language used, and ensuring that hyperbolic or misleading statements are flagged.\n",
      "\n",
      "**Critique of the Writing:**\n",
      "The article employs an evocative style, replete with nautical metaphors to enchant the reader into visualizing the digital transformation journey. This prose style effectively captures interest and maintains engagement while discussing potentially dense technical topics. However, critics may argue that the extended metaphor may convolute the company's tangible offerings by abstracting them into conceptual notions of navigation and exploration, potentially distracting from a clear understanding of its services and products.\n",
      "\n",
      "Additionally, the security attributes of Navida's products are addressed through metaphor as protection from the \"pirates of the digital age.\" While creative, the text should ensure that it substantiates these cybersecurity claims with objective information about the product's efficacy to prevent any misconception of their capabilities.\n",
      "\n",
      "The text also touches upon sustainability and environmental consciousness in the digital realm. While these mentions align with contemporary values and market trends, they require careful backing to avoid falling into the territory of greenwashing. Companies issuing statements about sustainability should support them with legitimate, verifiable actions and policies.\n",
      "\n",
      "Lastly, the conclusion posits Navida as a foundational component to prospects in digital innovation. While inspiring, it is critical that such claims are not unfounded or overly promotional without adequate evidence to back them up.\n",
      "\n",
      "In conclusion, while the text seems compliant regarding harmful content, it is essential for such writings to augment creative narratives with factual data, ensuring that metaphors and analogies do not overshadow concrete information about the company's offerings, standards, and values.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Writer):\n",
      "\n",
      "Upon evaluation, the provided text, \"Navida: Navigating the Digital Seas of Innovation,\" appears to be free of harmful content. The narrative constructs a metaphor linking digital innovation to seafaring, painting the company Navida as a trailblazer in technology akin to nautical exploration and guidance.\n",
      "\n",
      "The crafting of the review encompasses aspects such as technological progression, success mapping, workforce empowerment, and sustainable practices. It does so without any immediately apparent harmful language or violations of regulatory standards.\n",
      "\n",
      "However, the assessment of the piece's alignment with required guidelines extends beyond just checking for harmful content. It is also important to consider the tone, language, and claims made in the text. This reflection should be knowledgeable, balancing the persuasive language used, and ensuring that hyperbolic or misleading statements are flagged.\n",
      "\n",
      "**Critique of the Writing:**\n",
      "The article employs an evocative style, replete with nautical metaphors to enchant the reader into visualizing the digital transformation journey. This prose style effectively captures interest and maintains engagement while discussing potentially dense technical topics. However, critics may argue that the extended metaphor may convolute the company's tangible offerings by abstracting them into conceptual notions of navigation and exploration, potentially distracting from a clear understanding of its services and products.\n",
      "\n",
      "Additionally, the security attributes of Navida's products are addressed through metaphor as protection from the \"pirates of the digital age.\" While creative, the text should ensure that it substantiates these cybersecurity claims with objective information about the product's efficacy to prevent any misconception of their capabilities.\n",
      "\n",
      "The text also touches upon sustainability and environmental consciousness in the digital realm. While these mentions align with contemporary values and market trends, they require careful backing to avoid falling into the territory of greenwashing. Companies issuing statements about sustainability should support them with legitimate, verifiable actions and policies.\n",
      "\n",
      "Lastly, the conclusion posits Navida as a foundational component to prospects in digital innovation. While inspiring, it is critical that such claims are not unfounded or overly promotional without adequate evidence to back them up.\n",
      "\n",
      "In conclusion, while the text seems compliant regarding harmful content, it is essential for such writings to augment creative narratives with factual data, ensuring that metaphors and analogies do not overshadow concrete information about the company's offerings, standards, and values.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWriter\u001b[0m (to User):\n",
      "\n",
      "Thank you for the thoughtful critique. In response to your feedback, I will revise the text to ensure a clearer understanding of Navida's tangible services, substantiate claims about their cybersecurity measures, and provide concrete information regarding their sustainability efforts. Here’s the improved version:\n",
      "\n",
      "**Navida: The Vanguard of Digital Innovation**\n",
      "\n",
      "Welcome to the world of Navida, where cutting-edge technology isn't just an aspiration—it's a daily reality. As pioneers in the digital space, Navida has etched its mark by offering practical, transformative solutions that directly address the challenges of today's tech landscape.\n",
      "\n",
      "**A Spectrum of Digital Expertise**\n",
      "\n",
      "Navida's suite of services is expansive. They are renowned for their AI platforms that are redefining customer service, with chatbots that respond with stunning accuracy and empathy. Navida's cybersecurity is more than just metaphorical armor against digital threats—it is built upon advanced encryption protocols and regular security audits that fortify businesses against real-world data breaches and cyberattacks, with transparent reporting that clients can trust.\n",
      "\n",
      "**Guiding Through Innovation**\n",
      "\n",
      "As an innovation leader, Navida imparts its wisdom through analytics tools that help businesses anticipate market movements and consumer behavior. These tools aren't prophetic; they're practical, built from the latest data science that transform mountains of data into actionable insights.\n",
      "\n",
      "**Investing in Human Capital**\n",
      "\n",
      "Beyond technology, Navida invests in people. Their training programs are concrete in their content, providing certifications and skills in areas such as cloud computing, data science, and cybersecurity. Navida doesn't just predict the need for a skilled workforce; it actively produces it through well-structured and industry-relevant education modules.\n",
      "\n",
      "**Commitment to Sustainability**\n",
      "\n",
      "When it comes to sustainability, Navida's approach is as grounded as it is forward-thinking. They have implemented server optimization strategies that reduce their energy consumption, and they offer their clients cloud-based solutions that are both efficient and environmentally responsible. Navida's environmental policies are publicly available, showcasing their commitment to transparency and genuine eco-friendly practices.\n",
      "\n",
      "**Conclusion: Embarking on a Tangible Future**\n",
      "\n",
      "Navida isn't just preparing for the future of digital innovation; it is actively building it with every code written, every system implemented, and every client partnership forged. While the metaphor of a digital odyssey does evoke a sense of adventure, the truth is that Navida's impact is measurable, substantial, and continually evolving to meet the demands of our technologically-driven world.\n",
      "\n",
      "Join Navida as it steers the ship of progress into the thriving waters of digital opportunity. With real-world solutions and a tangible roadmap for tech excellence, Navida is not just a part of the digital innovation narrative—it's writing it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "critic_executor = autogen.UserProxyAgent(\n",
    "    name=\"Critic_Executor\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    # is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 1,\n",
    "        \"work_dir\": \"tasks\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")\n",
    "\n",
    "# one way of registering functions is to use the register_for_llm and register_for_execution decorators\n",
    "\n",
    "\n",
    "@critic_executor.register_for_execution()\n",
    "@critic.register_for_llm(name=\"check_harmful_content\", description=\"Check if content contain harmful keywords.\")\n",
    "def check_harmful_content(content: Annotated[str, \"Content to check if harmful keywords.\"]):\n",
    "    # List of harmful keywords for demonstration purposes\n",
    "    harmful_keywords = [\"violence\", \"hate\", \"bullying\", \"death\"]\n",
    "\n",
    "    # Normalize the input text to lower case to ensure case-insensitive matching\n",
    "    text = content.lower()\n",
    "\n",
    "    print(f\"Checking for harmful content...{text}\", \"yellow\")\n",
    "    # Check if any of the harmful keywords appear in the text\n",
    "    for keyword in harmful_keywords:\n",
    "        if keyword in text:\n",
    "            return \"Denied. Harmful content detected:\" + keyword  # Harmful content detected\n",
    "\n",
    "    return \"Approve. TERMINATE\"  # No harmful content detected\n",
    "\n",
    "\n",
    "def reflection_message_no_harm(recipient, messages, sender, config):\n",
    "    print(\"Reflecting...\", \"yellow\")\n",
    "    return f\"Reflect and provide critique on the following writing. Ensure it does not contain harmful content. You can use tools to check it. \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\n",
    "\n",
    "\n",
    "user_proxy.register_nested_chats(\n",
    "    [\n",
    "        {\n",
    "            \"sender\": critic_executor,\n",
    "            \"recipient\": critic,\n",
    "            \"message\": reflection_message_no_harm,\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        }\n",
    "    ],\n",
    "    trigger=writer,  # condition=my_condition,\n",
    ")\n",
    "\n",
    "res = user_proxy.initiate_chat(recipient=writer, message=task, max_turns=2, summary_method=\"last_msg\")"
   ]
  }
 ],
 "metadata": {
  "extra_files_to_copy": [
   "nested_chat_1.png",
   "nested_chat_2.png"
  ],
  "front_matter": {
   "description": "Solve complex tasks with a chat nested as inner monologue.",
   "tags": [
    "nested chat",
    "orchestration"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
